import 'package:incontext/core/utils/result.dart';
import 'package:incontext/features/context/domain/entities/context_entity.dart';
import 'package:incontext/features/context/domain/entities/prompt_definition_entity.dart';

class OutputGenerationResult {
  const OutputGenerationResult({
    required this.content,
  });

  final String content;
}

class DummyOutputGenerationService {
  const DummyOutputGenerationService();

  Future<Result<OutputGenerationResult>> generateOutput({
    required ContextEntity context,
    required PromptDefinitionEntity prompt,
  }) async {
    // Simulate API delay
    await Future.delayed(const Duration(seconds: 2));

    // Replace {{CONTEXT}} in template with actual context
    final processedPrompt = prompt.promptTemplate.replaceAll(
      '{{CONTEXT}}',
      context.content,
    );

    // Generate dummy output based on prompt type
    final output = '''
[Dummy output generated using prompt: "${prompt.name}" v${prompt.version}]

This is a placeholder output. In production, this would be generated by an LLM.

Processed prompt was:
---
$processedPrompt
---

Context used:
${context.content}
''';

    return Success(OutputGenerationResult(content: output.trim()));
  }
}
